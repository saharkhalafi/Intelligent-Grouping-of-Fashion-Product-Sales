# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MY4FQWTofUVTJB5CmDTeKomEGUJC-I6L
"""

# main.py

import pandas as pd
import numpy as np
from hazm import Normalizer, WordTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans


input_file = 'products.xlsx'
output_file_1 = 'output_keywords_clustering.xlsx'
output_file_2 = 'output_combination_clustering.xlsx'

num_clusters = 4000


df = pd.read_excel(input_file)


required_cols_1 = {'Product name', 'ordered_qty'}
if not required_cols_1.issubset(df.columns):
    raise ValueError("فایل باید شامل ستون‌های 'Product name' و 'ordered_qty' باشد.")


normalizer = Normalizer()
tokenizer = WordTokenizer()

def preprocess(text):
    text = str(text).strip()
    text = normalizer.normalize(text)
    tokens = tokenizer.tokenize(text)
    return " ".join(tokens)

df['normalized'] = df['Product name'].apply(preprocess)


vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=2000)
X = vectorizer.fit_transform(df['normalized'])

kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')
df['cluster'] = kmeans.fit_predict(X)



def top_terms_for_cluster(tfidf_matrix, labels, vectorizer, top_n=3):
    feature_names = vectorizer.get_feature_names_out()
    cluster_labels = {}
    for cluster_id in range(max(labels) + 1):
        cluster_indices = np.where(labels == cluster_id)[0]
        sub_matrix = tfidf_matrix[cluster_indices]
        mean_tfidf = np.asarray(sub_matrix.mean(axis=0)).ravel()
        top_indices = mean_tfidf.argsort()[::-1][:top_n]
        keywords = [feature_names[i] for i in top_indices]
        cluster_labels[cluster_id] = ' '.join(keywords)
    return cluster_labels

cluster_keywords = top_terms_for_cluster(X, df['cluster'].values, vectorizer)
df['cluster_label'] = df['cluster'].map(cluster_keywords)


result_keywords = df.groupby(['cluster_label', 'Type'])['ordered_qty'].sum().reset_index()
result_keywords = result_keywords.rename(columns={
    'cluster_label': 'ویژگی‌های مهم استخراج‌شده',
    'ordered_qty': 'مجموع فروش',
    'Type': 'نوع'
}).sort_values(by='مجموع فروش', ascending=False)

result_keywords.to_excel(output_file_1, index=False)
print(f"✅ خروجی ۱ ذخیره شد در: {output_file_1}")


required_cols_2 = {'Product name', 'Gender', 'ordered_qty', 'Color', 'Material', 'Type'}
if not required_cols_2.issubset(df.columns):
    raise ValueError("فایل باید شامل ستون‌های 'Product name', 'Gender', 'Color', 'Material', 'Type', 'ordered_qty' باشد.")

df['Product Group'] = (
    df['Type'].astype(str).str.strip() + ' ' +
    df['Gender'].astype(str).str.strip() + ' ' +
    df['Color'].astype(str).str.strip() + ' ' +
    df['Material'].astype(str).str.strip()
).str.strip()

result_combo = df.groupby(['Product Group', 'Type'])['ordered_qty'].sum().reset_index()
result_combo = result_combo.rename(columns={
    'Product Group': 'ویژگی‌های محصول',
    'ordered_qty': 'مجموع فروش',
    'Type': 'نوع'
}).sort_values(by='مجموع فروش', ascending=False)

result_combo.to_excel(output_file_2, index=False)
print(f"✅ خروجی ۲ ذخیره شد در: {output_file_2}")